# [필수] 간단한 자기 소개와 함께, 기존에 주로 해왔던 일 그리고 현재 하는 일을 상세하게 말씀해주세요. * 최대 1,000자 이내로 작성해주세요.

위대한상상(요기요)에서 Data Service팀 팀장으로 근무하며 대용량 데이터 처리 시스템 설계 및 개발, 데이터 플랫폼 구축, 백엔드 서비스 개발 업무를 수행해왔습니다.

요기요에서는 일 1억 건 이상의 사용자 행동 로그를 처리할 수 있는 아키텍처를 설계하고, 로그 품질을 60~70%에서 95% 이상으로 향상시켜 데이터 분석의 신뢰도를 크게 개선했습니다. 또한 배달 시간 예측 모델 실시간 서빙 시스템을 구축하여 트래픽 변화에 따른 실시간 컨테이너 오케스트레이션 및 대규모 트래픽을 소화할 수 있는 아키텍처를 설계하였고, 성능 모니터링 및 최적화를 통해 피크타임 기준 평균 응답시간을 100ms에서 20ms로 개선했습니다.

데이터 사이언티스트들의 업무 효율 증대를 위한 MLOps 플랫폼 구축 프로젝트에서는 ML 모델 학습부터 배포, 모니터링까지 전체 라이프사이클을 관리하는 시스템을 설계하고 구현했습니다. BentoML을 활용하여 ML 모델 패키징 및 서빙 환경을 표준화하고, 지속적 학습(Continuous Training) 파이프라인을 Airflow로 구축하여 모델의 정확도를 유지할 수 있게 했습니다.

기술적으로는 Java, Python, SQL을 활용한 백엔드 시스템 개발에 능숙하며, BigQuery, Hadoop, Hive와 같은 빅데이터 처리 도구를 활용한 데이터 파이프라인 구축 경험이 있습니다. GCP, AWS 등 클라우드 환경에서 Kubernetes와 Docker를 활용한 컨테이너 기반 서비스 개발 및 운영에도 익숙합니다.

제 강점은 대용량 데이터를 효율적으로 처리하는 분산 시스템 설계 능력, 실시간 데이터 처리 경험, ML 모델 서빙을 위한 데이터 파이프라인 구축 경험, 그리고 10명 규모의 다양한 직군으로 구성된 팀을 이끈 리더십 경험입니다. 이러한 경험과 역량을 바탕으로 KREAM의 데이터 인프라 개선 및 효율적인 데이터 활용을 위한 시스템 구축에 기여하고 싶습니다.

# [필수] 서비스 상세 설계 경험이 있다면 소개해 주세요. 작성 시에는 프로젝트 참여도/기여도 및 실제 성과에 대해서 자세하게 작성해 주세요. * 최대 1,000자 이내로 작성해주세요.

요기요에서 진행한 '사용자 행동 로그 관리 시스템(I.Log.Yo)' 프로젝트에서 아키텍처 설계부터 구현까지 전체 과정을 주도했습니다. 이 시스템은 다양한 앱(배달, 라이더, 사장님 등)에서 발생하는 일 1억 건 이상의 사용자 행동 로그를 수집, 검증, 처리하는 플랫폼입니다.

프로젝트 참여도/기여도:
- Project Tech Lead로서 전체 아키텍처 설계 및 개발 방향 수립 (기여도: 80%)
- 로그 스키마 표준화 및 검증 시스템 설계 및 개발 (기여도: 40%)
- 실시간/준실시간 데이터 수집 파이프라인 구축 (기여도: 40%)
- 4명 개발자(백엔드, 프론트엔드, 데이터 엔지니어)로 구성된 프로젝트팀 리딩

아키텍처 설계:
1. 로그 수집 계층: GA4(모바일 앱, 준실시간), BigQuery(준실시간) / 디버그 모바일 앱(실시간), GCP Pub/Sub(웹서비스, 실시간), 수집서버(FastAPI, 실시간)를 통해 다양한 소스에서 데이터 수집
2. 로그 검증 계층: FastAPI 기반의 실시간, Airflow를 통한 배치를 통한 스키마 검증 서비스 개발
3. 로그 저장 계층: BigQuery를 활용한 대용량 데이터 저장 및 관리
4. 로그 처리 계층: Airflow를 통한 ETL 파이프라인 구축 및 자동화
5. 데이터 서빙 계층: PostgreSQL, Redis 기반의 캐싱 레이어를 통한 고성능 API 개발

실제 성과:
- 로그 품질 향상(60~70% → 95% 이상)으로 데이터 분석의 신뢰도 크게 개선
- A/B 테스트 정확도 향상 및 데이터 기반 의사결정의 신뢰성 확보
- 실시간 모니터링을 통한 비정상 패턴 감지 및 신속한 대응 가능
- 안정적인 데이터 파이프라인 구축으로 마케팅 및 비즈니스 팀의 데이터 활용도 증가
- 확장 가능하고 유연한 아키텍처로 새로운 로그 요구사항에 빠르게 대응 가능

# [필수] 부서에 합류하게 된다면 기대하는 바(성취하고 싶은 부분)가 무엇인지 말씀해 주세요. * 최대 1,000자 이내로 작성해주세요.

KREAM이 데이터 기반 의사결정을 지원하는 안정적이고 확장 가능한 데이터 인프라를 구축하는 데 기여하고 싶습니다. 특히 다음과 같은 부분에서 성취와 기여를 기대합니다.

첫째, 효율적이고 안정적인 데이터 파이프라인 구축입니다. KREAM이 글로벌 서비스로 성장하기 위해서는 대용량 데이터를 효율적으로 처리할 수 있는 인프라가 필수적입니다. 일 1억 건 이상의 로그 데이터 처리 시스템 경험을 바탕으로, 데이터 수집부터 분석까지 전체 파이프라인을 최적화하고 비용 효율적으로 운영하는 데 기여하고 싶습니다.

둘째, 실시간 데이터 처리 시스템 구축입니다. 한정판 커머스의 특성상 실시간 가격 변동, 재고 현황, 사용자 행동 등을 빠르게 분석하고 대응하는 것이 중요합니다. Kafka, Pub/Sub 등을 활용한 실시간 데이터 처리 경험을 바탕으로 비즈니스 의사결정을 더욱 빠르고 정확하게 지원하고 싶습니다.

셋째, 머신러닝 데이터 파이프라인 구축입니다. 제품 추천, 가격 예측, 사기 거래 감지 등에 ML 모델을 활용할 수 있는 데이터 파이프라인을 구축하고 싶습니다. MLOps 플랫폼 구축 경험을 바탕으로 데이터 사이언티스트들이 모델 개발에 집중할 수 있는 환경을 제공하고 싶습니다.

넷째, 데이터 거버넌스와 품질 관리 시스템 구축입니다. 로그 스키마 표준화 및 검증 시스템 구축 경험을 바탕으로 데이터 품질을 향상시키고, 신뢰할 수 있는 데이터 기반 의사결정을 지원하고 싶습니다.

마지막으로, 비즈니스 인사이트 도출을 위한 데이터 서비스 개발입니다. 한정판 커머스 플랫폼의 특성을 고려한 맞춤형 데이터 서비스를 개발하여 내부 구성원들의 의사결정을 지원하고 싶습니다. 제품 가격 변동 분석, 트렌드 예측, 사용자 행동 패턴 분석 등 비즈니스 요구사항에 최적화된 데이터 마트와 시각화 대시보드를 구축하고 싶습니다.

KREAM의 "국내를 넘어 글로벌 서비스로 나아갈 때까지" 도전적인 과제들을 해결하며 함께 성장하고 싶습니다.

# [필수] 팀을 이뤄 협업을 하면서 성과를 이뤘던 경험을 적어주세요. 자신이 어떤 역할로 팀에 기여했고 어떤 교훈을 얻었는지를 포함해 주세요. * 최대 1,000자 이내로 작성해주세요.

요기요 배달 시간 예측 모델 실시간 서빙 서비스 구축 프로젝트에서 다양한 직군과 협업하며 큰 성과를 거둔 경험이 있습니다. 이 프로젝트는 주문 전/후 배달 예상 시간을 정확히 예측하기 위한 시스템으로, PO, Data Scientist, BE, FE, DE/MLOps, 비즈니스 분석가로 구성된 팀이 함께 진행했습니다.

저는 서비스 개발 파트 Project Tech Lead로 참여하여 전체 시스템 아키텍처 설계, 팀원 간 의사소통 조율, 기술적 의사결정을 주도했습니다. 특히 데이터 사이언티스트가 개발한 ML 모델을 실제 서비스에 적용하기 위한 인터페이스 설계 및 성능 최적화 부분에 집중했습니다.

가장 큰 도전 과제는 피크타임(점심/저녁 시간대)에 급증하는 트래픽을 안정적으로 처리하는 것이었습니다. 이를 해결하기 위해:

1. 마이크로서비스 아키텍처 설계: 기능별로 3개의 서비스(모델 서빙, 지리정보 연산, 가게 정보관리)로 분리하여 각 서비스의 독립적 확장이 가능하도록 했습니다.
2. 성능 최적화: Redis 클러스터 기반의 다중 레벨 캐싱을 구현하여 반복 쿼리를 최소화했습니다.
3. 사전 스케일링: 트래픽 패턴을 분석하여 피크타임 2시간 전에 자동으로 노드와 파드를 확장하는 CronJob을 설정했습니다.

이러한 접근으로 평균 응답 시간을 100ms에서 20ms로 개선했고, 서비스 안정성을 크게 향상시켰습니다. 이 프로젝트는 고객 경험 향상과 배달 운영 효율화에 직접적으로 기여했습니다.

이 경험을 통해 얻은 교훈은 다음과 같습니다:

첫째, 서로 다른 전문성을 가진 팀원들 간의 효과적인 소통이 중요합니다. 정기적인 지식 공유 세션을 통해 서로의 도메인에 대한 이해를 높였습니다.

둘째, 일시적인 해결책보다 지속 가능한 아키텍처 설계에 집중해야 장기적인 성과를 달성할 수 있습니다.

셋째, 데이터 기반 의사결정이 효과적입니다. 모든 성능 개선 작업은 철저한 모니터링과 측정을 기반으로 이루어졌으며, 이는 리소스의 효율적 활용과 비용 절감으로 이어졌습니다.

