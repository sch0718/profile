# [필수] 기존 직장에서의 퇴직 사유와 네이버파이낸셜로의 지원 동기를 자유롭게 기재해주세요. (500자 이내)

개발자로 입사해 4년 반 동안 팀장으로 성장하는 과정에서 많은 것을 배웠습니다. 그러나 조직이 커지면서 여러 프로젝트를 동시에 관리하게 되어 실제 코딩 업무에서 점차 멀어지게 되었고, 개발자로서의 전문성을 더 발전시키기 어려운 환경이었습니다.

경영난으로 희망퇴직 신청을 받았을 때, 이를 새로운 도전을 위한 기회로 받아들였습니다. 그동안 제대로 쉬어본 적 없이 달려온 시간을 돌아보며, 잠시 휴식을 통해 개발 역량을 다시 갈고닦는 시간을 가졌습니다.

네이버 멤버십 가입자로서 네이버페이를 주 결제 수단으로 사용하면서 그 편리함과 사용자 경험에 항상 감탄했습니다. 일상에서 결제할 때마다 이런 혁신적인 서비스를 만드는 기술력이 궁금했고, 이제는 사용자에서 개발자로서 이 가치를 함께 만들어가고 싶습니다. 쿠버네티스 기반의 MSA 아키텍처를 활용한 대규모 트래픽 처리 시스템 설계, 구축한 경험이 네이버페이의 안정성과 확장성 향상에 도움이 될 수 있기를 바랍니다. 

# [필수] 지금까지 수행한 과제 또는 프로젝트를 소개해주시고 본인의 역할을 함께 기술해주세요. (1000자 이내)

2022년 9월부터 2023년 3월까지 요기요의 배달 시간 예측 모델 실시간 서빙 서비스를 구축하는 프로젝트를 진행했습니다. 사용자가 주문 전/후에 정확한 배달 예상 시간을 제공받을 수 있도록 ML 모델을 서빙하고, 지속적인 학습을 통해 예측 정확도를 유지하는 시스템을 개발했습니다.

이 프로젝트에서 저는 Tech Lead로서 아키텍처 설계부터 백엔드 개발, ML 모델 서빙 파이프라인 구축까지 핵심적인 역할을 수행했습니다. 특히 쿠버네티스 기반의 MSA 아키텍처를 설계하고, GCP의 GKE를 활용하여 트래픽 변화에 유연하게 대응할 수 있는 시스템을 구축했습니다.

가장 큰 기술적 도전은 피크 시간대에 초당 수백 건의 예측 요청이 들어올 때 발생하는 처리 지연 문제였습니다. 이를 해결하기 위해:

1. 용도별 서비스 분리: 트래픽 특성에 따라 워크로드를 분리하여 독립적으로 스케일링되도록 설계
2. 컨테이너 경량화 및 최적화: FastAPI와 비동기 방식을 활용해 컨테이너 크기와 리소스 사용량 최적화
3. 효율적인 스케일 아웃 전략: CronJob을 활용해 피크 시간 이전에 미리 리소스를 확장하여 Cold Start 방지
4. 다층적 캐싱 전략: 서비스 특성에 맞춰 L1/L2 캐시를 전략적으로 적용

이러한 접근 방식을 통해 피크 시간대 응답 시간을 100ms에서 20ms 이하로 단축하는 성과를 달성했으며, 안정적인 서비스 운영을 가능하게 했습니다.

이 프로젝트를 통해 대규모 트래픽을 안정적으로 처리하는 분산 시스템 설계, 성능 최적화, 그리고 ML 모델의 실시간 서빙에 대한 깊은 이해를 얻었습니다. 이러한 경험은 네이버페이와 같은 대규모 결제 시스템에서도 중요한 응답 시간 보장, 트래픽 급증 대응, 서비스 안정성 확보에 직접 적용될 수 있을 것입니다. 특히 결제 과정에서의 즉각적인 응답과 안정성은 사용자 경험에 직결되는 중요한 요소로, 저의 경험이 네이버파이낸셜의 서비스 품질 향상에 기여할 수 있을 것으로 확신합니다.

# [선택] 프로그래밍 과정에서 기술의 원리를 고민해본 경험이 있다면 말씀해주세요.

배달 시간 예측 모델 서빙 서비스를 개발하면서 가장 깊이 탐구했던 기술적 원리는 파이썬의 비동기 프로그래밍입니다. 초기에는 동기식으로 개발했으나, 피크 시간대 초당 수백 건의 요청 처리 시 응답 시간이 급증하는 문제가 발생했습니다.

이 문제를 해결하기 위해 먼저 파이썬의 실행 제한 요소인 GIL(Global Interpreter Lock)의 한계를 이해했습니다. 파이썬은 여러 작업을 동시에 처리하는 멀티스레딩을 지원하지만, GIL 때문에 실제로는 한 번에 하나의 작업만 처리할 수 있어 CPU 작업에서는 병렬 처리가 어렵습니다. 하지만 I/O 작업이 많은 서비스에서는 비동기 방식이 효과적이라는 점을 파악했습니다.

FastAPI와 asyncio를 도입하여 모든 엔드포인트를 비동기 방식으로 재설계했습니다. 이 과정에서 특히 집중한 부분은 'asyncio의 이벤트 루프 작동 원리'였습니다. 이벤트 루프는 대기 중인 작업들을 관리하고, I/O 작업 완료 시까지 다른 작업을 처리할 수 있게 하는 메커니즘입니다. 이를 이해함으로써 코루틴 간 효율적 전환을 구현하고 불필요한 대기 시간을 최소화했습니다.

또한 비동기 환경에서의 데이터베이스 접근과 캐싱 전략도 최적화했습니다. Redis 클라이언트를 비동기 버전으로 교체하고, 데이터베이스 연결 풀을 비동기 방식으로 구성했습니다. 단순히 라이브러리 교체가 아닌, 시스템 전체가 효율적으로 작동하는 원리를 심층적으로 이해하는 과정이었습니다.

이러한 비동기 프로그래밍 원리의 적용으로 응답 시간을 100ms에서 20ms 이하로 단축했습니다. 더 중요한 것은 트래픽이 증가할수록 비동기 시스템의 이점이 두드러져 선형적 성능 저하가 아닌 안정적 서비스 제공이 가능해진 점입니다.

이 경험을 통해 기술을 단순히 적용하는 것을 넘어, 그 원리를 깊이 이해하고 시스템 특성에 맞게 최적화하는 것의 중요성을 배웠습니다.